{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ДЗ ##\n",
    "1. Попробуйте починить сеть по словам, сделанную на уроке.\n",
    "\n",
    "2. Попробуйте изменить параметры нейронной сети, генерирующей текст таким образом, чтобы добиться генерации как можно более осмысленного текста. Пришлите лучший текст из получившихся и опишите предпринятые для его получения действия. Можно использовать текст другого произведения.\n",
    "\n",
    "### Решение ###\n",
    "В попытках починить сеть и одновременно изменить ее параметры для генерации как можно более осмысленного текста, пришел к выводу о том, что необходимо использование Embedding слоя.\n",
    "Изменил функцию buildPhrase, увеличил число слов maxWordsCount = 5000 и взял текст побольше. Результаты впечатлили. После 50 эпох accuracy: 0.9960 и первозданный текст Александра Сергеевича."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "PH_mcB21EoxE"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "bJQINrKnDqju"
   },
   "outputs": [],
   "source": [
    "with open('onegin.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    text = text.replace('\\ufeff', '') # убираем первый невидимый символ\n",
    "    text = re.sub(r'[^А-я ]', '', text) # убираем все недопустимые символы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "SubXLsi5ErEN",
    "outputId": "a1195ebc-bf1e-480e-a8c3-515036b53f09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Мой дядя самых честных правилКогда не в шутку занемогОн уважать себя заставилИ лучше выдумать не мог'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fyD7g4glKVps",
    "outputId": "abe937c1-231e-4616-c5fb-6c1fc6e2d77d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10663"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "IJD76YJ4E6z0"
   },
   "outputs": [],
   "source": [
    "num_characters = 34 #33 буквы + пробел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "DgiJrgsiIK_x"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Input, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "appv1wfpIJvH"
   },
   "outputs": [],
   "source": [
    "maxWordsCount = 5000\n",
    "tokenizer = Tokenizer(num_words=num_characters, char_level=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "N1yoi7pGId-n"
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QJmXPaQbIf-I",
    "outputId": "06f4ad70-1f61-428d-e789-f876f3033f67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, 'о': 2, 'е': 3, 'а': 4, 'н': 5, 'и': 6, 'т': 7, 'л': 8, 'с': 9, 'в': 10, 'р': 11, 'м': 12, 'д': 13, 'к': 14, 'у': 15, 'п': 16, 'ы': 17, 'ь': 18, 'й': 19, 'г': 20, 'б': 21, 'з': 22, 'я': 23, 'ч': 24, 'ж': 25, 'х': 26, 'ш': 27, 'ю': 28, 'ц': 29, 'ф': 30, 'щ': 31, 'э': 32, 'ъ': 33}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "1wWs_206JRu-"
   },
   "outputs": [],
   "source": [
    "inp_chars = 6 #\n",
    "data = tokenizer.texts_to_matrix(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yqy7uBYCJTYV",
    "outputId": "f4f078a2-a14b-4d4e-ab1a-65029d4566e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HnWQb42jKAd1",
    "outputId": "f495a242-3799-4523-a0ce-22b76c56bba5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10657"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = data.shape[0]-inp_chars\n",
    "n  #размер обучающего множества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "kvZ-iB9LKwgc"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "_nG7M5RIKsfs"
   },
   "outputs": [],
   "source": [
    "X = np.array([data[i:i+inp_chars, :] for i in range(n)])\n",
    "Y = data[inp_chars:] #предсказание следующего символа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z20DCMmSK3tj",
    "outputId": "8c4d6938-ea09-4058-f4a0-af19c3029b56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10657"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0NrELysIK5fL",
    "outputId": "7f4e2cf6-4fff-4078-c9bc-d9f5270154f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XbsyrcEGK7G7",
    "outputId": "523ea8a9-48a8-4da2-f2de-49f1a04cd246"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "lIP7yhRzLZsr"
   },
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gwyYcqGiLXPE",
    "outputId": "697cf7e3-d48a-4f60-f34c-55d188b3c914"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_3 (SimpleRNN)    (None, 500)               267500    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 34)                17034     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 284,534\n",
      "Trainable params: 284,534\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input((inp_chars, num_characters)))\n",
    "model.add(SimpleRNN(500, activation='tanh'))\n",
    "model.add(Dense(num_characters, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y3-y2cQiMGLK",
    "outputId": "380ed148-247e-46dc-f809-e98e4d62b1d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "334/334 [==============================] - 5s 11ms/step - loss: 2.9792 - accuracy: 0.1596\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.7192 - accuracy: 0.2072\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.6403 - accuracy: 0.2199\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.6071 - accuracy: 0.2185\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 2.5733 - accuracy: 0.2313\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.5686 - accuracy: 0.2221\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.5643 - accuracy: 0.2307\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.5608 - accuracy: 0.2281\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 2.5466 - accuracy: 0.2322\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 2.5318 - accuracy: 0.2310\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 2.5443 - accuracy: 0.2328\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 2.5337 - accuracy: 0.2308\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 2.5460 - accuracy: 0.2287\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 2.5131 - accuracy: 0.2383\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.4984 - accuracy: 0.2433\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 2.4996 - accuracy: 0.2423\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 2.4900 - accuracy: 0.2417\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 2.4873 - accuracy: 0.2443\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.4786 - accuracy: 0.2441\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 2.4771 - accuracy: 0.2476\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 2.4706 - accuracy: 0.2466\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 2.4681 - accuracy: 0.2534\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.4653 - accuracy: 0.2471\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.4515 - accuracy: 0.2468\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 2.4480 - accuracy: 0.2536\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 2.4398 - accuracy: 0.2488\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.4403 - accuracy: 0.2590\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.4214 - accuracy: 0.2579\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.4176 - accuracy: 0.2626\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.4009 - accuracy: 0.2629\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 2.4003 - accuracy: 0.2642\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.3907 - accuracy: 0.2726\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.3907 - accuracy: 0.2693\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.3680 - accuracy: 0.2701\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.3664 - accuracy: 0.2785\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 2.3600 - accuracy: 0.2844\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 2.3439 - accuracy: 0.2828\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.3144 - accuracy: 0.2880\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.3159 - accuracy: 0.2913\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 2.3042 - accuracy: 0.2972\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.3041 - accuracy: 0.2935\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.2759 - accuracy: 0.3047\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.2617 - accuracy: 0.3117\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.2580 - accuracy: 0.3108\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 4s 10ms/step - loss: 2.2413 - accuracy: 0.3076\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.2270 - accuracy: 0.3212\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.2079 - accuracy: 0.3213\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.1789 - accuracy: 0.3290\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.1516 - accuracy: 0.3363\n",
      "Epoch 50/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.1438 - accuracy: 0.3427\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.1462 - accuracy: 0.3378\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.1122 - accuracy: 0.3440\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.0741 - accuracy: 0.3603\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.0495 - accuracy: 0.3637\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.0024 - accuracy: 0.3796\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 2.0167 - accuracy: 0.3778\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 1.9906 - accuracy: 0.3835\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 1.9338 - accuracy: 0.4026\n",
      "Epoch 59/100\n",
      "334/334 [==============================] - 4s 10ms/step - loss: 1.9131 - accuracy: 0.4084\n",
      "Epoch 60/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 1.9160 - accuracy: 0.4084\n",
      "Epoch 61/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 1.8865 - accuracy: 0.4091\n",
      "Epoch 62/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 1.8040 - accuracy: 0.4370\n",
      "Epoch 63/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 1.8158 - accuracy: 0.4292\n",
      "Epoch 64/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 1.7599 - accuracy: 0.4479\n",
      "Epoch 65/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 1.7450 - accuracy: 0.4548\n",
      "Epoch 66/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 1.7046 - accuracy: 0.4657\n",
      "Epoch 67/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 1.6674 - accuracy: 0.4763\n",
      "Epoch 68/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 1.6621 - accuracy: 0.4760\n",
      "Epoch 69/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 1.5706 - accuracy: 0.5118\n",
      "Epoch 70/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 1.5668 - accuracy: 0.5063\n",
      "Epoch 71/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 1.5346 - accuracy: 0.5236\n",
      "Epoch 72/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 1.4882 - accuracy: 0.5303\n",
      "Epoch 73/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 1.4566 - accuracy: 0.5372\n",
      "Epoch 74/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 1.4413 - accuracy: 0.5427\n",
      "Epoch 75/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 1.3684 - accuracy: 0.5623\n",
      "Epoch 76/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 1.3788 - accuracy: 0.5624\n",
      "Epoch 77/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 1.3541 - accuracy: 0.5703\n",
      "Epoch 78/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 1.3067 - accuracy: 0.5887\n",
      "Epoch 79/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 1.2764 - accuracy: 0.5940\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/334 [==============================] - 4s 11ms/step - loss: 1.1900 - accuracy: 0.6255\n",
      "Epoch 81/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 1.2738 - accuracy: 0.5958\n",
      "Epoch 82/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 1.1389 - accuracy: 0.6434\n",
      "Epoch 83/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 1.1581 - accuracy: 0.6356\n",
      "Epoch 84/100\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 1.1165 - accuracy: 0.6449\n",
      "Epoch 85/100\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 1.0353 - accuracy: 0.6728\n",
      "Epoch 86/100\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 1.0328 - accuracy: 0.6725\n",
      "Epoch 87/100\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.9955 - accuracy: 0.6835\n",
      "Epoch 88/100\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.9264 - accuracy: 0.7129\n",
      "Epoch 89/100\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.9247 - accuracy: 0.7078\n",
      "Epoch 90/100\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.9058 - accuracy: 0.7156\n",
      "Epoch 91/100\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.9447 - accuracy: 0.7017\n",
      "Epoch 92/100\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 1.0221 - accuracy: 0.6721\n",
      "Epoch 93/100\n",
      "334/334 [==============================] - 4s 13ms/step - loss: 0.8564 - accuracy: 0.7305\n",
      "Epoch 94/100\n",
      "334/334 [==============================] - 4s 12ms/step - loss: 0.9803 - accuracy: 0.6853\n",
      "Epoch 95/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 0.8033 - accuracy: 0.7523\n",
      "Epoch 96/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 0.8524 - accuracy: 0.7285\n",
      "Epoch 97/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 0.7570 - accuracy: 0.7637\n",
      "Epoch 98/100\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 0.7893 - accuracy: 0.7538\n",
      "Epoch 99/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 0.7278 - accuracy: 0.7741\n",
      "Epoch 100/100\n",
      "334/334 [==============================] - 3s 10ms/step - loss: 0.8178 - accuracy: 0.7385\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "history = model.fit(X, Y, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "s0_LNL2pMiku"
   },
   "outputs": [],
   "source": [
    "def buildPhrase(inp_str, str_len = 50):\n",
    "  for i in range(str_len):\n",
    "    x = []\n",
    "    for j in range(i, i+inp_chars):\n",
    "      x.append(tokenizer.texts_to_matrix(inp_str[j])) # преобразуем символы в One-Hot-encoding\n",
    "\n",
    "    x = np.array(x)\n",
    "    inp = x.reshape(1, inp_chars, num_characters)\n",
    "\n",
    "    pred = model.predict( inp ) # предсказываем OHE четвертого символа\n",
    "    d = tokenizer.index_word[pred.argmax(axis=1)[0]] # получаем ответ в символьном представлении\n",
    "\n",
    "    inp_str += d # дописываем строку\n",
    "\n",
    "  return inp_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7-vxdO-dMijp",
    "outputId": "d81ed2a6-53fd-4120-8297-706043ef0518"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 184ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 167ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 252ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "Мой дядядя ь меменонеко   ва олс  авб еенсгитах  рннеоом к\n"
     ]
    }
   ],
   "source": [
    "res = buildPhrase(\"Мой дядя\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Lp6XvkoOYyH"
   },
   "source": [
    "# Слова\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "_-Wq8QJ2PDM2"
   },
   "outputs": [],
   "source": [
    "with open('onegin.txt', 'r', encoding='utf-8') as f:\n",
    "    texts = f.read()\n",
    "    texts = texts.replace('\\ufeff', '') # убираем первый невидимый символ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "revghpcNPQSd"
   },
   "outputs": [],
   "source": [
    "maxWordsCount = 5000\n",
    "tokenizer = Tokenizer(num_words=maxWordsCount, filters='!–\"—#$%&amp;()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r«»',\n",
    "                       lower=True, split=' ', char_level=False)\n",
    "tokenizer.fit_on_texts([texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HPga89Z4PVFe",
    "outputId": "057e9610-e34d-4c95-e931-b33aa6341ece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('мой', 10), ('дядя', 1), ('самых', 1), ('честных', 1), ('правил', 1), ('когда', 7), ('не', 26), ('в', 42), ('шутку', 1), ('занемог', 1)]\n"
     ]
    }
   ],
   "source": [
    "dist = list(tokenizer.word_counts.items())\n",
    "print(dist[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "7mpCwwYQP5hV"
   },
   "outputs": [],
   "source": [
    "data = tokenizer.texts_to_sequences([texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tPDrhzF4P7Lk",
    "outputId": "65631086-6381-43a2-8405-9e068d7de72d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[15,\n",
       "  212,\n",
       "  213,\n",
       "  214,\n",
       "  215,\n",
       "  23,\n",
       "  4,\n",
       "  2,\n",
       "  216,\n",
       "  217,\n",
       "  3,\n",
       "  218,\n",
       "  58,\n",
       "  219,\n",
       "  1,\n",
       "  89,\n",
       "  220,\n",
       "  4,\n",
       "  16,\n",
       "  9,\n",
       "  221,\n",
       "  222,\n",
       "  90,\n",
       "  11,\n",
       "  91,\n",
       "  15,\n",
       "  223,\n",
       "  224,\n",
       "  17,\n",
       "  225,\n",
       "  226,\n",
       "  1,\n",
       "  92,\n",
       "  1,\n",
       "  227,\n",
       "  4,\n",
       "  228,\n",
       "  93,\n",
       "  229,\n",
       "  230,\n",
       "  231,\n",
       "  232,\n",
       "  233,\n",
       "  234,\n",
       "  94,\n",
       "  38,\n",
       "  235,\n",
       "  236,\n",
       "  237,\n",
       "  238,\n",
       "  239,\n",
       "  240,\n",
       "  1,\n",
       "  95,\n",
       "  241,\n",
       "  58,\n",
       "  23,\n",
       "  31,\n",
       "  242,\n",
       "  243,\n",
       "  244,\n",
       "  39,\n",
       "  245,\n",
       "  246,\n",
       "  247,\n",
       "  248,\n",
       "  2,\n",
       "  96,\n",
       "  5,\n",
       "  249,\n",
       "  250,\n",
       "  251,\n",
       "  252,\n",
       "  253,\n",
       "  32,\n",
       "  59,\n",
       "  254,\n",
       "  24,\n",
       "  97,\n",
       "  255,\n",
       "  1,\n",
       "  256,\n",
       "  17,\n",
       "  257,\n",
       "  258,\n",
       "  259,\n",
       "  40,\n",
       "  260,\n",
       "  261,\n",
       "  31,\n",
       "  262,\n",
       "  263,\n",
       "  264,\n",
       "  41,\n",
       "  20,\n",
       "  265,\n",
       "  15,\n",
       "  266,\n",
       "  267,\n",
       "  5,\n",
       "  268,\n",
       "  269,\n",
       "  25,\n",
       "  98,\n",
       "  99,\n",
       "  270,\n",
       "  12,\n",
       "  100,\n",
       "  271,\n",
       "  15,\n",
       "  272,\n",
       "  13,\n",
       "  273,\n",
       "  274,\n",
       "  1,\n",
       "  6,\n",
       "  11,\n",
       "  275,\n",
       "  276,\n",
       "  10,\n",
       "  277,\n",
       "  278,\n",
       "  279,\n",
       "  2,\n",
       "  280,\n",
       "  281,\n",
       "  282,\n",
       "  283,\n",
       "  284,\n",
       "  285,\n",
       "  9,\n",
       "  101,\n",
       "  286,\n",
       "  42,\n",
       "  287,\n",
       "  288,\n",
       "  1,\n",
       "  289,\n",
       "  102,\n",
       "  290,\n",
       "  291,\n",
       "  292,\n",
       "  293,\n",
       "  43,\n",
       "  60,\n",
       "  26,\n",
       "  44,\n",
       "  294,\n",
       "  103,\n",
       "  61,\n",
       "  295,\n",
       "  296,\n",
       "  297,\n",
       "  21,\n",
       "  298,\n",
       "  11,\n",
       "  104,\n",
       "  61,\n",
       "  299,\n",
       "  300,\n",
       "  301,\n",
       "  302,\n",
       "  62,\n",
       "  4,\n",
       "  303,\n",
       "  304,\n",
       "  305,\n",
       "  9,\n",
       "  306,\n",
       "  105,\n",
       "  4,\n",
       "  307,\n",
       "  308,\n",
       "  309,\n",
       "  106,\n",
       "  26,\n",
       "  310,\n",
       "  107,\n",
       "  1,\n",
       "  2,\n",
       "  311,\n",
       "  312,\n",
       "  313,\n",
       "  314,\n",
       "  23,\n",
       "  31,\n",
       "  315,\n",
       "  316,\n",
       "  317,\n",
       "  318,\n",
       "  63,\n",
       "  63,\n",
       "  319,\n",
       "  1,\n",
       "  320,\n",
       "  108,\n",
       "  61,\n",
       "  321,\n",
       "  109,\n",
       "  322,\n",
       "  110,\n",
       "  15,\n",
       "  20,\n",
       "  5,\n",
       "  323,\n",
       "  324,\n",
       "  14,\n",
       "  325,\n",
       "  326,\n",
       "  8,\n",
       "  43,\n",
       "  111,\n",
       "  327,\n",
       "  43,\n",
       "  111,\n",
       "  112,\n",
       "  328,\n",
       "  329,\n",
       "  1,\n",
       "  102,\n",
       "  330,\n",
       "  45,\n",
       "  3,\n",
       "  14,\n",
       "  331,\n",
       "  113,\n",
       "  16,\n",
       "  332,\n",
       "  1,\n",
       "  333,\n",
       "  334,\n",
       "  335,\n",
       "  336,\n",
       "  1,\n",
       "  337,\n",
       "  338,\n",
       "  339,\n",
       "  28,\n",
       "  64,\n",
       "  340,\n",
       "  45,\n",
       "  114,\n",
       "  7,\n",
       "  3,\n",
       "  341,\n",
       "  1,\n",
       "  342,\n",
       "  104,\n",
       "  46,\n",
       "  115,\n",
       "  343,\n",
       "  344,\n",
       "  116,\n",
       "  117,\n",
       "  1,\n",
       "  8,\n",
       "  117,\n",
       "  39,\n",
       "  345,\n",
       "  346,\n",
       "  347,\n",
       "  65,\n",
       "  118,\n",
       "  119,\n",
       "  348,\n",
       "  20,\n",
       "  21,\n",
       "  14,\n",
       "  349,\n",
       "  350,\n",
       "  351,\n",
       "  352,\n",
       "  1,\n",
       "  353,\n",
       "  354,\n",
       "  355,\n",
       "  11,\n",
       "  66,\n",
       "  356,\n",
       "  66,\n",
       "  357,\n",
       "  120,\n",
       "  358,\n",
       "  359,\n",
       "  121,\n",
       "  360,\n",
       "  361,\n",
       "  362,\n",
       "  17,\n",
       "  363,\n",
       "  364,\n",
       "  365,\n",
       "  366,\n",
       "  122,\n",
       "  367,\n",
       "  27,\n",
       "  17,\n",
       "  368,\n",
       "  123,\n",
       "  3,\n",
       "  369,\n",
       "  370,\n",
       "  40,\n",
       "  371,\n",
       "  2,\n",
       "  372,\n",
       "  373,\n",
       "  67,\n",
       "  124,\n",
       "  106,\n",
       "  17,\n",
       "  125,\n",
       "  374,\n",
       "  375,\n",
       "  376,\n",
       "  377,\n",
       "  2,\n",
       "  378,\n",
       "  379,\n",
       "  1,\n",
       "  380,\n",
       "  381,\n",
       "  33,\n",
       "  382,\n",
       "  383,\n",
       "  384,\n",
       "  385,\n",
       "  34,\n",
       "  386,\n",
       "  387,\n",
       "  68,\n",
       "  39,\n",
       "  126,\n",
       "  388,\n",
       "  64,\n",
       "  389,\n",
       "  3,\n",
       "  69,\n",
       "  390,\n",
       "  14,\n",
       "  391,\n",
       "  62,\n",
       "  392,\n",
       "  393,\n",
       "  394,\n",
       "  395,\n",
       "  396,\n",
       "  2,\n",
       "  397,\n",
       "  127,\n",
       "  398,\n",
       "  128,\n",
       "  47,\n",
       "  399,\n",
       "  128,\n",
       "  400,\n",
       "  401,\n",
       "  402,\n",
       "  403,\n",
       "  404,\n",
       "  405,\n",
       "  129,\n",
       "  4,\n",
       "  40,\n",
       "  406,\n",
       "  34,\n",
       "  407,\n",
       "  130,\n",
       "  408,\n",
       "  3,\n",
       "  409,\n",
       "  4,\n",
       "  123,\n",
       "  410,\n",
       "  2,\n",
       "  411,\n",
       "  96,\n",
       "  412,\n",
       "  131,\n",
       "  11,\n",
       "  132,\n",
       "  413,\n",
       "  414,\n",
       "  48,\n",
       "  415,\n",
       "  67,\n",
       "  133,\n",
       "  132,\n",
       "  416,\n",
       "  3,\n",
       "  2,\n",
       "  417,\n",
       "  49,\n",
       "  418,\n",
       "  134,\n",
       "  4,\n",
       "  419,\n",
       "  10,\n",
       "  420,\n",
       "  135,\n",
       "  4,\n",
       "  421,\n",
       "  4,\n",
       "  16,\n",
       "  3,\n",
       "  422,\n",
       "  48,\n",
       "  423,\n",
       "  8,\n",
       "  46,\n",
       "  93,\n",
       "  424,\n",
       "  425,\n",
       "  107,\n",
       "  426,\n",
       "  427,\n",
       "  428,\n",
       "  429,\n",
       "  430,\n",
       "  431,\n",
       "  1,\n",
       "  21,\n",
       "  432,\n",
       "  433,\n",
       "  29,\n",
       "  434,\n",
       "  70,\n",
       "  435,\n",
       "  35,\n",
       "  136,\n",
       "  8,\n",
       "  436,\n",
       "  437,\n",
       "  1,\n",
       "  71,\n",
       "  438,\n",
       "  1,\n",
       "  439,\n",
       "  4,\n",
       "  440,\n",
       "  441,\n",
       "  38,\n",
       "  23,\n",
       "  442,\n",
       "  443,\n",
       "  444,\n",
       "  101,\n",
       "  137,\n",
       "  9,\n",
       "  4,\n",
       "  16,\n",
       "  1,\n",
       "  131,\n",
       "  445,\n",
       "  2,\n",
       "  446,\n",
       "  124,\n",
       "  7,\n",
       "  69,\n",
       "  22,\n",
       "  138,\n",
       "  447,\n",
       "  72,\n",
       "  448,\n",
       "  11,\n",
       "  2,\n",
       "  71,\n",
       "  3,\n",
       "  449,\n",
       "  21,\n",
       "  139,\n",
       "  7,\n",
       "  69,\n",
       "  3,\n",
       "  450,\n",
       "  32,\n",
       "  451,\n",
       "  7,\n",
       "  140,\n",
       "  10,\n",
       "  452,\n",
       "  453,\n",
       "  1,\n",
       "  454,\n",
       "  1,\n",
       "  455,\n",
       "  1,\n",
       "  141,\n",
       "  7,\n",
       "  456,\n",
       "  457,\n",
       "  92,\n",
       "  9,\n",
       "  458,\n",
       "  459,\n",
       "  24,\n",
       "  460,\n",
       "  90,\n",
       "  134,\n",
       "  108,\n",
       "  461,\n",
       "  462,\n",
       "  463,\n",
       "  26,\n",
       "  7,\n",
       "  464,\n",
       "  465,\n",
       "  3,\n",
       "  73,\n",
       "  142,\n",
       "  466,\n",
       "  1,\n",
       "  467,\n",
       "  2,\n",
       "  468,\n",
       "  2,\n",
       "  469,\n",
       "  470,\n",
       "  471,\n",
       "  472,\n",
       "  49,\n",
       "  8,\n",
       "  143,\n",
       "  16,\n",
       "  3,\n",
       "  473,\n",
       "  474,\n",
       "  475,\n",
       "  476,\n",
       "  477,\n",
       "  478,\n",
       "  479,\n",
       "  144,\n",
       "  480,\n",
       "  481,\n",
       "  482,\n",
       "  483,\n",
       "  1,\n",
       "  484,\n",
       "  485,\n",
       "  145,\n",
       "  486,\n",
       "  8,\n",
       "  487,\n",
       "  21,\n",
       "  3,\n",
       "  488,\n",
       "  8,\n",
       "  489,\n",
       "  490,\n",
       "  2,\n",
       "  491,\n",
       "  492,\n",
       "  8,\n",
       "  493,\n",
       "  494,\n",
       "  146,\n",
       "  495,\n",
       "  496,\n",
       "  8,\n",
       "  3,\n",
       "  70,\n",
       "  147,\n",
       "  58,\n",
       "  8,\n",
       "  148,\n",
       "  9,\n",
       "  21,\n",
       "  497,\n",
       "  1,\n",
       "  498,\n",
       "  499,\n",
       "  1,\n",
       "  500,\n",
       "  27,\n",
       "  501,\n",
       "  149,\n",
       "  502,\n",
       "  503,\n",
       "  8,\n",
       "  3,\n",
       "  70,\n",
       "  144,\n",
       "  504,\n",
       "  105,\n",
       "  505,\n",
       "  506,\n",
       "  507,\n",
       "  508,\n",
       "  509,\n",
       "  510,\n",
       "  511,\n",
       "  94,\n",
       "  512,\n",
       "  513,\n",
       "  514,\n",
       "  515,\n",
       "  50,\n",
       "  516,\n",
       "  517,\n",
       "  1,\n",
       "  518,\n",
       "  519,\n",
       "  520,\n",
       "  521,\n",
       "  522,\n",
       "  523,\n",
       "  1,\n",
       "  524,\n",
       "  525,\n",
       "  526,\n",
       "  150,\n",
       "  527,\n",
       "  528,\n",
       "  529,\n",
       "  530,\n",
       "  1,\n",
       "  74,\n",
       "  531,\n",
       "  532,\n",
       "  533,\n",
       "  1,\n",
       "  534,\n",
       "  535,\n",
       "  536,\n",
       "  537,\n",
       "  538,\n",
       "  2,\n",
       "  539,\n",
       "  8,\n",
       "  143,\n",
       "  16,\n",
       "  18,\n",
       "  3,\n",
       "  540,\n",
       "  150,\n",
       "  541,\n",
       "  542,\n",
       "  23,\n",
       "  28,\n",
       "  543,\n",
       "  544,\n",
       "  38,\n",
       "  545,\n",
       "  59,\n",
       "  8,\n",
       "  3,\n",
       "  546,\n",
       "  547,\n",
       "  548,\n",
       "  549,\n",
       "  151,\n",
       "  550,\n",
       "  11,\n",
       "  12,\n",
       "  551,\n",
       "  552,\n",
       "  17,\n",
       "  44,\n",
       "  553,\n",
       "  12,\n",
       "  97,\n",
       "  9,\n",
       "  554,\n",
       "  555,\n",
       "  556,\n",
       "  557,\n",
       "  558,\n",
       "  559,\n",
       "  1,\n",
       "  560,\n",
       "  561,\n",
       "  1,\n",
       "  562,\n",
       "  152,\n",
       "  563,\n",
       "  564,\n",
       "  565,\n",
       "  566,\n",
       "  567,\n",
       "  568,\n",
       "  1,\n",
       "  569,\n",
       "  570,\n",
       "  3,\n",
       "  22,\n",
       "  2,\n",
       "  571,\n",
       "  30,\n",
       "  153,\n",
       "  572,\n",
       "  573,\n",
       "  7,\n",
       "  574,\n",
       "  2,\n",
       "  575,\n",
       "  576,\n",
       "  42,\n",
       "  577,\n",
       "  5,\n",
       "  578,\n",
       "  579,\n",
       "  13,\n",
       "  580,\n",
       "  154,\n",
       "  13,\n",
       "  581,\n",
       "  582,\n",
       "  155,\n",
       "  28,\n",
       "  583,\n",
       "  15,\n",
       "  584,\n",
       "  17,\n",
       "  585,\n",
       "  586,\n",
       "  3,\n",
       "  19,\n",
       "  587,\n",
       "  156,\n",
       "  588,\n",
       "  119,\n",
       "  589,\n",
       "  2,\n",
       "  590,\n",
       "  591,\n",
       "  157,\n",
       "  592,\n",
       "  593,\n",
       "  594,\n",
       "  595,\n",
       "  27,\n",
       "  596,\n",
       "  597,\n",
       "  158,\n",
       "  20,\n",
       "  75,\n",
       "  5,\n",
       "  598,\n",
       "  1,\n",
       "  13,\n",
       "  599,\n",
       "  5,\n",
       "  600,\n",
       "  601,\n",
       "  602,\n",
       "  603,\n",
       "  4,\n",
       "  604,\n",
       "  38,\n",
       "  605,\n",
       "  18,\n",
       "  606,\n",
       "  2,\n",
       "  607,\n",
       "  3,\n",
       "  608,\n",
       "  159,\n",
       "  159,\n",
       "  24,\n",
       "  609,\n",
       "  610,\n",
       "  611,\n",
       "  612,\n",
       "  613,\n",
       "  9,\n",
       "  614,\n",
       "  615,\n",
       "  30,\n",
       "  51,\n",
       "  616,\n",
       "  617,\n",
       "  618,\n",
       "  619,\n",
       "  620,\n",
       "  3,\n",
       "  621,\n",
       "  7,\n",
       "  13,\n",
       "  18,\n",
       "  622,\n",
       "  9,\n",
       "  623,\n",
       "  160,\n",
       "  1,\n",
       "  624,\n",
       "  2,\n",
       "  625,\n",
       "  626,\n",
       "  627,\n",
       "  628,\n",
       "  629,\n",
       "  52,\n",
       "  44,\n",
       "  161,\n",
       "  162,\n",
       "  163,\n",
       "  630,\n",
       "  161,\n",
       "  162,\n",
       "  163,\n",
       "  631,\n",
       "  24,\n",
       "  632,\n",
       "  633,\n",
       "  634,\n",
       "  164,\n",
       "  635,\n",
       "  1,\n",
       "  636,\n",
       "  637,\n",
       "  165,\n",
       "  50,\n",
       "  166,\n",
       "  164,\n",
       "  638,\n",
       "  639,\n",
       "  1,\n",
       "  640,\n",
       "  641,\n",
       "  642,\n",
       "  76,\n",
       "  643,\n",
       "  644,\n",
       "  645,\n",
       "  1,\n",
       "  646,\n",
       "  647,\n",
       "  22,\n",
       "  648,\n",
       "  649,\n",
       "  650,\n",
       "  651,\n",
       "  652,\n",
       "  653,\n",
       "  654,\n",
       "  11,\n",
       "  655,\n",
       "  656,\n",
       "  151,\n",
       "  657,\n",
       "  7,\n",
       "  658,\n",
       "  659,\n",
       "  660,\n",
       "  661,\n",
       "  662,\n",
       "  663,\n",
       "  664,\n",
       "  665,\n",
       "  666,\n",
       "  667,\n",
       "  668,\n",
       "  669,\n",
       "  167,\n",
       "  20,\n",
       "  670,\n",
       "  30,\n",
       "  671,\n",
       "  25,\n",
       "  672,\n",
       "  673,\n",
       "  146,\n",
       "  674,\n",
       "  675,\n",
       "  168,\n",
       "  51,\n",
       "  676,\n",
       "  168,\n",
       "  51,\n",
       "  677,\n",
       "  24,\n",
       "  678,\n",
       "  2,\n",
       "  679,\n",
       "  169,\n",
       "  680,\n",
       "  681,\n",
       "  682,\n",
       "  683,\n",
       "  684,\n",
       "  10,\n",
       "  685,\n",
       "  62,\n",
       "  77,\n",
       "  686,\n",
       "  9,\n",
       "  687,\n",
       "  170,\n",
       "  13,\n",
       "  2,\n",
       "  688,\n",
       "  689,\n",
       "  690,\n",
       "  691,\n",
       "  692,\n",
       "  149,\n",
       "  693,\n",
       "  694,\n",
       "  695,\n",
       "  1,\n",
       "  696,\n",
       "  697,\n",
       "  13,\n",
       "  698,\n",
       "  699,\n",
       "  700,\n",
       "  701,\n",
       "  702,\n",
       "  703,\n",
       "  17,\n",
       "  704,\n",
       "  705,\n",
       "  706,\n",
       "  13,\n",
       "  171,\n",
       "  707,\n",
       "  708,\n",
       "  709,\n",
       "  139,\n",
       "  152,\n",
       "  13,\n",
       "  710,\n",
       "  711,\n",
       "  712,\n",
       "  59,\n",
       "  713,\n",
       "  714,\n",
       "  715,\n",
       "  13,\n",
       "  1,\n",
       "  172,\n",
       "  716,\n",
       "  717,\n",
       "  718,\n",
       "  719,\n",
       "  720,\n",
       "  721,\n",
       "  722,\n",
       "  173,\n",
       "  723,\n",
       "  172,\n",
       "  724,\n",
       "  725,\n",
       "  726,\n",
       "  1,\n",
       "  727,\n",
       "  728,\n",
       "  729,\n",
       "  34,\n",
       "  133,\n",
       "  730,\n",
       "  731,\n",
       "  174,\n",
       "  2,\n",
       "  732,\n",
       "  175,\n",
       "  733,\n",
       "  734,\n",
       "  735,\n",
       "  53,\n",
       "  176,\n",
       "  166,\n",
       "  736,\n",
       "  24,\n",
       "  737,\n",
       "  738,\n",
       "  13,\n",
       "  13,\n",
       "  177,\n",
       "  739,\n",
       "  167,\n",
       "  740,\n",
       "  178,\n",
       "  179,\n",
       "  741,\n",
       "  179,\n",
       "  742,\n",
       "  7,\n",
       "  12,\n",
       "  25,\n",
       "  12,\n",
       "  743,\n",
       "  15,\n",
       "  744,\n",
       "  745,\n",
       "  19,\n",
       "  746,\n",
       "  31,\n",
       "  36,\n",
       "  12,\n",
       "  747,\n",
       "  36,\n",
       "  748,\n",
       "  749,\n",
       "  4,\n",
       "  750,\n",
       "  41,\n",
       "  751,\n",
       "  36,\n",
       "  ...]]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fA6DuYkoQS8N",
    "outputId": "9dd76c8e-cd06-4cb6-8941-908c99ae0530"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1996"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ILtfEKKIQH2d",
    "outputId": "b7bb8b2d-0a3f-40ba-bc24-3ff502ef458a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1996,)\n"
     ]
    }
   ],
   "source": [
    "data = tokenizer.texts_to_sequences([texts])\n",
    "res = np.array( data[0] )\n",
    "print( res.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "pVSmTo2qQyer"
   },
   "outputs": [],
   "source": [
    "inp_words = 3\n",
    "n = res.shape[0] - inp_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "_ljnZUqXQ3Zz"
   },
   "outputs": [],
   "source": [
    "X = np.array([res[i:i + inp_words] for i in range(n)])\n",
    "Y = to_categorical(res[inp_words:], num_classes=maxWordsCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yc8dLHkSQ9Nr",
    "outputId": "687a26dd-46ed-4b6a-a37c-07b4fe243b44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 3, 256)            1280000   \n",
      "                                                                 \n",
      " simple_rnn_5 (SimpleRNN)    (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5000)              1285000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,696,328\n",
      "Trainable params: 2,696,328\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 3s 35ms/step - loss: 8.2771 - accuracy: 0.0326\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 6.9139 - accuracy: 0.0447\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 6.4656 - accuracy: 0.0462\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 5.8673 - accuracy: 0.0597\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 4.9331 - accuracy: 0.1305\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 3.7784 - accuracy: 0.3312\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 2.6385 - accuracy: 0.5981\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 1.7440 - accuracy: 0.7381\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 2s 38ms/step - loss: 1.1510 - accuracy: 0.8108\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.7944 - accuracy: 0.8736\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.5831 - accuracy: 0.9052\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.4375 - accuracy: 0.9423\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.3326 - accuracy: 0.9644\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.2611 - accuracy: 0.9724\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.2018 - accuracy: 0.9794\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.1562 - accuracy: 0.9829\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 2s 38ms/step - loss: 0.1280 - accuracy: 0.9844\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.1049 - accuracy: 0.9905\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.0863 - accuracy: 0.9905\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.0743 - accuracy: 0.9895\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.0645 - accuracy: 0.9940\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.0568 - accuracy: 0.9955\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.0522 - accuracy: 0.9960\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0440 - accuracy: 0.9945\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.0451 - accuracy: 0.9940\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 2s 34ms/step - loss: 0.0375 - accuracy: 0.9945\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.0333 - accuracy: 0.9955\n",
      "Epoch 28/50\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.0297 - accuracy: 0.9955\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.0302 - accuracy: 0.9970\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.0284 - accuracy: 0.9955\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.0250 - accuracy: 0.9960\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.0234 - accuracy: 0.9955\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.0231 - accuracy: 0.9945\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.0206 - accuracy: 0.9970\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0193 - accuracy: 0.9970\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0182 - accuracy: 0.9970\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0193 - accuracy: 0.9970\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0198 - accuracy: 0.9950\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0169 - accuracy: 0.9960\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 2s 38ms/step - loss: 0.0159 - accuracy: 0.9965\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0161 - accuracy: 0.9960\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.0145 - accuracy: 0.9965\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0143 - accuracy: 0.9965\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0148 - accuracy: 0.9950\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.0137 - accuracy: 0.9965\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 2s 35ms/step - loss: 0.0126 - accuracy: 0.9965\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0120 - accuracy: 0.9970\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0118 - accuracy: 0.9965\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 2s 38ms/step - loss: 0.0120 - accuracy: 0.9955\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0129 - accuracy: 0.9960\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(maxWordsCount, 256, input_length = inp_words))\n",
    "model.add(SimpleRNN(256, activation='tanh'))\n",
    "model.add(Dense(maxWordsCount, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "history = model.fit(X, Y, batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "WiPb0RnqRJiT"
   },
   "outputs": [],
   "source": [
    "def buildPhrase(texts, str_len = 40):\n",
    "    res = texts\n",
    "    data = tokenizer.texts_to_sequences([texts])[0]\n",
    "    for i in range(str_len):\n",
    "        x = data[i: i + inp_words]\n",
    "        inp = np.expand_dims(x, axis=0)\n",
    "\n",
    "        pred = model.predict(inp)\n",
    "        indx = pred.argmax(axis=1)[0]\n",
    "        data.append(indx)\n",
    "\n",
    "        res += \" \" + tokenizer.index_word[indx]  # дописываем строку\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 197ms/step\n",
      "1/1 [==============================] - 0s 215ms/step\n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 202ms/step\n",
      "1/1 [==============================] - 0s 206ms/step\n",
      "1/1 [==============================] - 0s 207ms/step\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 165ms/step\n",
      "мой дядя самых честных правил когда не в шутку занемог он уважать себя заставил и лучше выдумать не мог его пример другим наука но боже мой какая скука с больным сидеть и день и ночь не отходя ни шагу прочь какое низкое коварство\n"
     ]
    }
   ],
   "source": [
    "res = buildPhrase(\"мой дядя самых\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9CEjebYVUpuH",
    "outputId": "6fa57ce5-fe21-495e-a01e-cd3b37435d74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512, 1000)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "v2L7ReIFRUuz",
    "outputId": "02b09bb1-a21d-4e18-8d0f-18d8c3c5f1fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 160ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "театр уж полон ложи блещут партер и кресла всё кипит в райке нетерпеливо плещут и взвившись занавес шумит блистательна полувоздушна смычку волшебному послушна толпою нимф окружена стоит истомина она одной ногой касаясь пола другою медленно кружит и вдруг прыжок и вдруг летит летит\n"
     ]
    }
   ],
   "source": [
    "res = buildPhrase(\"театр уж полон\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
